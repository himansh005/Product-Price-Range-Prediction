# -*- coding: utf-8 -*-
"""IndiaMART_Phase2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PG_rgris_QIZdcvdd6eOMDbNQxl_R6qg

# IndiaMart PriceRangePrediction

New Section


```
# To Achieve the target, we have assumed the following things:

      1. 85% and above prices should be retained after outlier detection for finding the price range.
      2. Units which have counts < 5 are removed.
     
```


```
# The following ensemble technique is used to find outliers:

        1. Isolation Forests - IF
        2. DBScan
        3. LOF
        4. MaxVote(IF, DBScan, LOF)
```

```

# For estimation of amount of contamination, Inter-Quartile Range Data is considered. If Data(IQR)==100%, it is set to 98% and if <=85%, it is set to 87%
```

The **contamination**  factor and **epsilon** value are not fixed and infered dynamically by the above technique. Primary test indicate robust nature of this technique.

##Imports
"""

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt

import numpy as np 
import pandas as pd 

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from scipy import stats

"""##Data Preprocessing

1. Remove items with count < 5
2. Consolidation and Organization
"""

data = pd.read_csv("Data-Table 1.csv")

data = data.drop(columns={"Subcat name", "PC_ITEM_ID", "PC_ITEM_NAME", })
data  = data.rename(index=str, columns={"Mcat Name": "MCAT", "FK_IM_SPEC_MASTER_DESC": "ISQ", "FK_IM_SPEC_OPTIONS_DESC":"ISQ Options", "PC_ITEM_FOB_PRICE":"Prices","PC_ITEM_MOQ_UNIT_TYPE":"Unit"})


#for non isq
data1=data.drop(columns={"ISQ", "ISQ Options"})
data1 = data1.groupby(['MCAT','Unit'])
data1 = data1.filter(lambda x: x['Unit'].count() > 5)
data1 = data1.groupby(['MCAT','Unit'])


#for isq
data2 = data.groupby(['MCAT','Unit','ISQ','ISQ Options'])
data2 = data2.filter(lambda x: x['ISQ Options'].count() > 5)
data2 = data2.groupby(['MCAT','Unit','ISQ','ISQ Options'])

data1.describe()

data2.describe()

"""# Driver Program

**The Main Ensembled Function**
"""

chunks = []
names = []

for name,c in data1:
  chunks.append(pd.DataFrame({"Price":c['Prices']}))
  names.append(name)
  
chunks2 = []
names2 = []
for name,c in data2:
  chunks2.append(pd.DataFrame({"Price":c['Prices']}))
  names2.append(name)

col_names =  ['MCAT Name', 'Unit', 'Unit Wise Min Price', 'Unit Wise Max Price', 'Most Common Price 1', 'Most Common Price 2', 'Most Common Price 3']
my_df1  = pd.DataFrame()
my_df2  = pd.DataFrame()

def findPriceRange(datas,contamination_factor,seed_percentage):
    
    datas = datas.sort_values(by=['Price'])
    datax = datas
    datay = datas
    dataz = datas
    
    original_std = np.std(np.array(datas))
    
    print("Seed Percentage :",seed_percentage, end=" ")
    print("Contamination: ",contamination_factor)
    print("original_std : ",original_std)
                      

    ######_____Isolation Forests

    isolation_forest = IsolationForest(contamination=contamination_factor, behaviour="new")
    if_vote = isolation_forest.fit_predict(dataz['Price'].values.reshape(-1,1))
    ######_____DBScan
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.cluster import DBSCAN
     
    scaler = MinMaxScaler()
    sd = scaler.fit_transform(datax)
    sd = pd.DataFrame(sd,columns=['Price'])
    
    
    outlier_detection = DBSCAN(eps = getHyperparameters(sd,seed_percentage) ,metric="euclidean",min_samples = 3,n_jobs = -1)
    clusters = outlier_detection.fit_predict(sd)
    clusters[clusters!=-1]=1
    
    dbscan_vote = clusters
    
    ######_____Local Outlier Factor
    clf = LocalOutlierFactor(n_neighbors=20, contamination=contamination_factor)
    y_pred = clf.fit_predict(np.array(datay['Price']).reshape(-1,1))
    X_scores = clf.negative_outlier_factor_

    lof_vote = y_pred
    
    ###genetic mixing
    
    
    v1 = if_vote 
    v1[v1>0] = 1
    v1[v1<0]=0
   
    v2 = dbscan_vote
    v2[v2>0] = 1
    v2[v2<0] = 0
                        
    v3 = lof_vote

    v3[v3>0] = 1
    v3[v3<0] = 0
    
      
    v4 = v1 + v2
    v4[v4>0] = 1
    v4[v4<0] = 0
    
    v5 = v2 + v3
    v5[v5>0] = 1
    v5[v5<0] = 0                      
                          
    v6 = v1 + v3
    v6[v6>0] = 1
    v6[v6<0] = 0 
     
    v7 = v1 + v2 + v3
    
    v7[v7<2] = 0
    v7[v7!=0] = 1
    
    
    l = ["v1", "v2", "v3", "v4", "v5", "v6", "v7"]
    index = {"v1":v1, "v2":v2, "v3":v3, "v4":v4, "v5":v5, "v6":v6, "v7":v7}
    
    minn = original_std+1
    best = []
    k = 0
    for i in l:
        
        t = index[i]*np.array(dataz['Price'])
        t = np.trim_zeros(t)
        k  = np.std(np.array(t))
        if(k<minn):
          minn = k
          best = t
    
    min_price, max_price = np.min(best), np.max(best)           
        


    return(min_price, max_price, best)

def threeModes(dataChunk):
  
  dataChunk2 = dataChunk
  m1=0
  m2=0
  m3=0
 
  m1 = int(stats.mode(dataChunk2)[0])
  dataChunk2 = dataChunk2[dataChunk2 != m1]
  
  if(len(dataChunk2)!=0):
    m2 = int(stats.mode(dataChunk2)[0])
    
    dataChunk2 = dataChunk2[dataChunk2 != m2]
  if(len(dataChunk2)!=0):
    m3 = int(stats.mode(dataChunk2)[0])
  


  return([m1, m2, m3])

def plot_figure(x,c,u,min_price,max_price):
    
    k = x
    fig, ax = plt.subplots()
    num_bins = 10
    n, bins, patches = ax.hist(k['Price'], num_bins, color=['grey'])
    d = ax.fill_betweenx(n,min_price,max_price,color='g',alpha=0.5)
    ax.set_xlabel('Prices')
    ax.set_ylabel('Counts')
    ax.set_title(r'Histogram for item-'+ c +' and unit - '+ u)
    fig.tight_layout()
    plt.show()

def getHyperparameters(sd,retain):
  
  import math
  
  dis=[]
  temp =list(sd['Price'])
  for i in range(0,len(temp)-1):
    dis.append(temp[i+1]-temp[i])

  arr = np.array(dis)
  diss = pd.DataFrame(dis,columns=['dis'])
  std=diss['dis'].std()
  ma = diss['dis'].max()
  n=len(dis)
  
  cnt={}
  unique_dis=list(set(dis))
  for i in unique_dis:
    cnt[i]=dis.count(i)
  keys = cnt.keys()
  keys=sorted(keys)
  cands=[]
  full = int(round((retain*n),0))
  for i in keys:
    full = full - cnt[i]
    cands.append(i)
    if(full<=0):
      break
    
  
  b = pd.DataFrame(cands)
  epsilon = round(np.max(np.array(b))*1000,0)/1000
  
  if(epsilon==0):
    epsilon=0.5
    
  print("Epsilon: ",epsilon)
  return(epsilon)

def estimateContamination(dataChunk):
  
  #index column addition
  unnormal_data=pd.DataFrame(dataChunk)

  # Computing IQR
  Q1 = unnormal_data['Price'].quantile(0.25)
  Q3 = unnormal_data['Price'].quantile(0.75)
  IQR = Q3 - Q1 

  import random
  label_data = list(unnormal_data['Price'])
  t=[]
  for i in range(len(unnormal_data['Price'])):
    if( (label_data[i] <= (Q1 - 1.5 * IQR)) or (label_data[i] >= (Q3 + 1.5 * IQR))):
      pass
    else:
      t.append(label_data[i])

  filtered = t
  
  
  #keep seed percentage == IQR range or 85% or 98%
  #assume 85%-98% purityz
  

 # double IQR
  
  import math
    
  seed_percentage  = math.floor((len(filtered)/len(unnormal_data))*100)
  if(seed_percentage<=85):
    seed_percentage = 88
  elif(seed_percentage>=99):
    seed_percentage = 88
    
  contamination_factor=0.5*((100-seed_percentage)/100) 
   

  
  return([seed_percentage, contamination_factor, filtered])


##________________________________________## DRIVER PROGRAM ##_________________________________________##

debug = 0

for i in range(len(chunks)):
  contam = estimateContamination(chunks[i])
  minn, maxx, pdata = findPriceRange(chunks[i],contam[1], contam[0])
  t = threeModes(pdata)
  my_df1 = my_df1.append({'MCAT Name': names[i][0], 'Unit': names[i][1], 'Unit Wise Min Price': minn, 'Unit Wise Max Price': maxx, 'Most Common Price 1':t[0], 'Most Common Price 2':t[1], 'Most Common Price 3':t[2] }, ignore_index=True)

for i in range(len(chunks2)):
  
  contam = estimateContamination(chunks2[i])
  minn, maxx, pdata = findPriceRange(chunks2[i],contam[1], contam[0])
  my_df2 = my_df2.append({'MCAT Name': names2[i][0], 'Unit': names2[i][1], 'ISQ Name' : names2[i][2], 'ISQ Options' :names2[i][3], 'ISQ Min Price': minn, 'ISQ Max Price': maxx}, ignore_index=True)

my_df1 = my_df1[col_names]
my_df2 = my_df2[['MCAT Name', 'Unit', 'ISQ Name', 'ISQ Options', 'ISQ Min Price', 'ISQ Max Price']]

final_df = pd.merge(my_df1, my_df2,how='left',left_on=('MCAT Name', 'Unit'), right_on=('MCAT Name', 'Unit'))
final_df = final_df.replace(np.nan, '---', regex=True)
final_df

final_df.to_csv("output.csv")

